# render.yaml
# This file defines the services for deploying the real-time ML pipeline on Render.

disks:
  - name: pipeline-data
    sizeGB: 1 # Smallest size, sufficient for this project

services:
  # 1. Kafka is now external (e.g., Upstash/Confluent).
  # You will set the KAFKA_* environment variables in the Render dashboard
  # for each service that needs them. The self-hosted Kafka service is removed.

  # 2. The Streamlit Dashboard
  - type: web
    name: dashboard
    env: python
    plan: starter # Upgrade to prevent spin-down for a better UX
    buildCommand: pip install -r requirements.txt
    startCommand: streamlit run dashboard/training_monitor.py --server.port $PORT --server.address 0.0.0.0
    envVars:
      - key: PYTHONUNBUFFERED # Ensures logs appear in real-time
        value: 1
    disk:
      name: pipeline-data
      mountPath: /data


  # 3. The Data Producer as a Background Worker
  - type: worker
    name: producer
    env: python
    plan: starter # CRITICAL: Upgrade to prevent spin-down
    buildCommand: pip install -r requirements.txt
    startCommand: python ingestion/producer.py
    envVars: # KAFKA_BOOTSTRAP will be added manually in Render UI
      - key: PYTHONUNBUFFERED
        value: 1
    disk:
      name: pipeline-data
      mountPath: /data

  # 4. The Bronze, Silver, and Trainer workers (all need the disk)
  - type: worker
    name: bronze-consumer
    env: python
    plan: starter # CRITICAL: Upgrade to prevent spin-down
    buildCommand: pip install -r requirements.txt
    startCommand: python transform/consumer_to_parquet.py
    envVars:
      - key: PYTHONUNBUFFERED
        value: 1
    disk:
      name: pipeline-data
      mountPath: /data

  - type: worker
    name: silver-consumer
    env: python
    plan: starter # CRITICAL: Upgrade to prevent spin-down
    buildCommand: pip install -r requirements.txt
    startCommand: python transform/consumer_to_silver.py
    envVars:
      - key: PYTHONUNBUFFERED
        value: 1
    disk:
      name: pipeline-data
      mountPath: /data

  - type: worker
    name: trainer
    env: python
    plan: starter # CRITICAL: Upgrade to prevent spin-down
    buildCommand: pip install -r requirements.txt
    startCommand: python transform/consumer_trainer.py
    envVars:
      - key: PYTHONUNBUFFERED
        value: 1
    disk:
      name: pipeline-data
      mountPath: /data
